{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/261 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ca480b996e540abb610df4c8b6f0a01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/636 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5666cc8db1f8468d99d86aa8c6e1caf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "10830367ee884ae798653f57f467c3ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/459 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c207efd4a149436a81905381c1287c77"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "228dd32227c5449491fc23a6a808effe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92eea0451e9c45e099946419b2933386"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Hello World.\n",
      "Prediction: NONE\n",
      "Against: 0.1198737695813179\n",
      "Favor: 0.1275908499956131\n",
      "Neutral: 0.752535343170166\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# select mode path here\n",
    "# see more at https://huggingface.co/kornosk\n",
    "# pretrained_LM_path = \"kornosk/bert-election2020-twitter-stance-biden\"\n",
    "# pretrained_LM_path = \"kornosk/bert-election2020-twitter-stance-trump\"\n",
    "pretrained_LM_path = \"kornosk/bert-election2020-twitter-stance-biden-KE-MLM\"\n",
    "# pretrained_LM_path = \"kornosk/bert-election2020-twitter-stance-trump-KE-MLM\"\n",
    "\n",
    "# load model\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_LM_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_LM_path)\n",
    "\n",
    "id2label = {\n",
    "    0: \"AGAINST\",\n",
    "    1: \"FAVOR\",\n",
    "    2: \"NONE\"\n",
    "}\n",
    "\n",
    "##### Prediction Neutral #####\n",
    "sentence = \"Hello World.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Prediction:\", id2label[np.argmax(predicted_probability)])\n",
    "print(\"Against:\", predicted_probability[0])\n",
    "print(\"Favor:\", predicted_probability[1])\n",
    "print(\"Neutral:\", predicted_probability[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Go Go Biden!!!\n",
      "Prediction: FAVOR\n",
      "Against: 0.2655964493751526\n",
      "Favor: 0.4986375868320465\n",
      "Neutral: 0.23576593399047852\n"
     ]
    }
   ],
   "source": [
    "##### Prediction Favor #####\n",
    "sentence = \"Go Go Biden!!!\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Prediction:\", id2label[np.argmax(predicted_probability)])\n",
    "print(\"Against:\", predicted_probability[0])\n",
    "print(\"Favor:\", predicted_probability[1])\n",
    "print(\"Neutral:\", predicted_probability[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Biden is the worst.\n",
      "Prediction: AGAINST\n",
      "Against: 0.397975355386734\n",
      "Favor: 0.33325299620628357\n",
      "Neutral: 0.2687717080116272\n"
     ]
    }
   ],
   "source": [
    "##### Prediction Against #####\n",
    "sentence = \"Biden is the worst.\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Prediction:\", id2label[np.argmax(predicted_probability)])\n",
    "print(\"Against:\", predicted_probability[0])\n",
    "print(\"Favor:\", predicted_probability[1])\n",
    "print(\"Neutral:\", predicted_probability[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Actual Science doesnt start until you have a testable hypothesis\n",
      "Prediction: NONE\n",
      "Against: 0.17915207147598267\n",
      "Favor: 0.08446616679430008\n",
      "Neutral: 0.7363817691802979\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Actual Science doesnt start until you have a testable hypothesis\"\n",
    "\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "predicted_probability = torch.softmax(outputs[0], dim=1)[0].tolist()\n",
    "\n",
    "print(\"Sentence:\", sentence)\n",
    "print(\"Prediction:\", id2label[np.argmax(predicted_probability)])\n",
    "print(\"Against:\", predicted_probability[0])\n",
    "print(\"Favor:\", predicted_probability[1])\n",
    "print(\"Neutral:\", predicted_probability[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}